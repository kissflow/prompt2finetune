{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kissflow/prompt2finetune/blob/main/amazon_review_mcp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "827e5d78",
      "metadata": {
        "id": "827e5d78"
      },
      "source": [
        "# Amazon Review Summarizer\n",
        "\n",
        "This notebook demonstrates how to use Firecrawl MCP (Model Context Protocol) server to scrape Amazon product reviews and OpenAI GPT-4o-mini to generate intelligent summaries using chain-of-thought prompting.\n",
        "\n",
        "## What is Firecrawl?\n",
        "Firecrawl is an MCP server that provides web scraping and crawling capabilities, making it easy to extract content from websites like Amazon product pages programmatically.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c372c12",
      "metadata": {
        "id": "3c372c12"
      },
      "source": [
        "## Installation\n",
        "\n",
        "First, install the required Python MCP SDK and OpenAI client:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c8274ed",
      "metadata": {
        "id": "7c8274ed"
      },
      "outputs": [],
      "source": [
        "%pip install mcp openai"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7be4421f",
      "metadata": {
        "id": "7be4421f"
      },
      "source": [
        "## Setup and Configuration\n",
        "\n",
        "Import necessary libraries and set up the MCP client and OpenAI:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c704c09",
      "metadata": {
        "id": "3c704c09"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import asyncio\n",
        "import json\n",
        "import re\n",
        "from mcp import ClientSession, StdioServerParameters\n",
        "from mcp.client.stdio import stdio_client\n",
        "from openai import OpenAI\n",
        "\n",
        "# Set your API keys\n",
        "FIRECRAWL_API_KEY = \"YOUR_FIRECRAWL_API_KEY\"  # Replace with your actual Firecrawl API key\n",
        "OPENAI_API_KEY = \"YOUR_OPENAI_API_KEY\"  # Replace with your actual OpenAI API key\n",
        "\n",
        "os.environ[\"FIRECRAWL_API_KEY\"] = FIRECRAWL_API_KEY\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "# Initialize OpenAI client\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "293cf231",
      "metadata": {
        "id": "293cf231"
      },
      "source": [
        "## Firecrawl MCP Client\n",
        "\n",
        "Create a helper class to manage the Firecrawl MCP client connection:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "286d55a9",
      "metadata": {
        "id": "286d55a9"
      },
      "outputs": [],
      "source": [
        "class FirecrawlClient:\n",
        "    def __init__(self, api_key):\n",
        "        self.api_key = api_key\n",
        "        self.session = None\n",
        "        self.client = None\n",
        "\n",
        "    async def __aenter__(self):\n",
        "        # Configure server parameters\n",
        "        server_params = StdioServerParameters(\n",
        "            command=\"npx\",\n",
        "            args=[\"-y\", \"firecrawl-mcp\"],\n",
        "            env={\n",
        "                \"FIRECRAWL_API_KEY\": self.api_key\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # Create stdio client\n",
        "        stdio_transport = await stdio_client(server_params).__aenter__()\n",
        "        self.client = stdio_transport\n",
        "\n",
        "        # Create session\n",
        "        self.session = await ClientSession(\n",
        "            stdio_transport[0],\n",
        "            stdio_transport[1]\n",
        "        ).__aenter__()\n",
        "\n",
        "        # Initialize the session\n",
        "        await self.session.initialize()\n",
        "\n",
        "        return self\n",
        "\n",
        "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
        "        if self.session:\n",
        "            await self.session.__aexit__(exc_type, exc_val, exc_tb)\n",
        "        if self.client:\n",
        "            await self.client.__aexit__(exc_type, exc_val, exc_tb)\n",
        "\n",
        "    async def list_tools(self):\n",
        "        \"\"\"List available tools from the Firecrawl MCP server\"\"\"\n",
        "        result = await self.session.list_tools()\n",
        "        return result.tools\n",
        "\n",
        "    async def call_tool(self, tool_name, arguments):\n",
        "        \"\"\"Call a tool with the given arguments\"\"\"\n",
        "        result = await self.session.call_tool(tool_name, arguments)\n",
        "        return result\n",
        "\n",
        "    async def scrape_url(self, url, extract_reviews=True):\n",
        "        \"\"\"Scrape a URL and optionally extract reviews\"\"\"\n",
        "        args = {\"url\": url}\n",
        "        if extract_reviews:\n",
        "            args[\"extract_reviews\"] = True\n",
        "\n",
        "        result = await self.call_tool(\"scrape\", args)\n",
        "        return result\n",
        "\n",
        "    def extract_amazon_reviews(self, scraped_content):\n",
        "        \"\"\"Extract review data from scraped Amazon content\"\"\"\n",
        "        reviews = []\n",
        "\n",
        "        # This is a simplified extraction - in practice, you'd use more sophisticated parsing\n",
        "        # Look for review patterns in the scraped content\n",
        "        if isinstance(scraped_content, dict) and 'content' in scraped_content:\n",
        "            content = scraped_content['content']\n",
        "\n",
        "            # Extract review text and ratings using regex patterns\n",
        "            review_pattern = r'(?:rating|star).*?(\\d+).*?(?:out of|/).*?5'\n",
        "            reviews_text = re.findall(r'\"(?:review|comment).*?\"(.*?)\"', content, re.IGNORECASE)\n",
        "\n",
        "            for i, review_text in enumerate(reviews_text[:10]):  # Limit to first 10 reviews\n",
        "                if len(review_text.strip()) > 20:  # Only include substantial reviews\n",
        "                    reviews.append({\n",
        "                        'text': review_text.strip(),\n",
        "                        'rating': None,  # Would need more sophisticated parsing\n",
        "                        'review_id': i\n",
        "                    })\n",
        "\n",
        "        return reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5daf03e4",
      "metadata": {
        "id": "5daf03e4"
      },
      "source": [
        "## OpenAI Integration for Review Summarization\n",
        "\n",
        "Create functions for chain-of-thought prompting with OpenAI GPT-4o-mini:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c7573b1",
      "metadata": {
        "id": "3c7573b1"
      },
      "outputs": [],
      "source": [
        "def summarize_reviews_chain_of_thought(reviews, detail_level=\"brief\"):\n",
        "    \"\"\"\n",
        "    Use chain-of-thought prompting to summarize Amazon reviews\n",
        "    \"\"\"\n",
        "    if not reviews:\n",
        "        return \"No reviews found to analyze.\"\n",
        "\n",
        "    # Prepare review text for analysis\n",
        "    review_texts = [review['text'] for review in reviews if review['text']]\n",
        "    combined_reviews = \"\\n\\n\".join(review_texts[:20])  # Limit to first 20 reviews\n",
        "\n",
        "    if detail_level == \"brief\":\n",
        "        prompt = f\"\"\"\n",
        "Let's analyze these Amazon product reviews step by step:\n",
        "\n",
        "Step 1: Identify the main themes and topics mentioned\n",
        "Step 2: Assess the overall sentiment (positive, negative, mixed)\n",
        "Step 3: Extract key insights about the product\n",
        "\n",
        "Reviews to analyze:\n",
        "{combined_reviews}\n",
        "\n",
        "Please provide a brief summary (2-3 sentences) following this chain of thought.\n",
        "\"\"\"\n",
        "    else:  # detailed\n",
        "        prompt = f\"\"\"\n",
        "Let's analyze these Amazon product reviews step by step:\n",
        "\n",
        "Step 1: Extract and categorize all review ratings (if mentioned)\n",
        "Step 2: Identify common positive themes and what customers love\n",
        "Step 3: Identify common negative themes and complaints\n",
        "Step 4: Analyze sentiment distribution\n",
        "Step 5: Generate comprehensive summary with pros/cons breakdown\n",
        "\n",
        "Reviews to analyze:\n",
        "{combined_reviews}\n",
        "\n",
        "Please provide a detailed analysis following this chain of thought, including:\n",
        "- Overall sentiment and rating trends\n",
        "- Key positive themes\n",
        "- Main complaints or issues\n",
        "- Final recommendation summary\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = openai_client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert at analyzing product reviews and providing insightful summaries.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=1000 if detail_level == \"brief\" else 2000,\n",
        "            temperature=0.3\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error generating summary: {str(e)}\"\n",
        "\n",
        "def compare_products_summary(product_summaries):\n",
        "    \"\"\"\n",
        "    Compare multiple product reviews using chain-of-thought\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "Let's compare these product reviews step by step:\n",
        "\n",
        "Step 1: Analyze each product's strengths and weaknesses\n",
        "Step 2: Compare overall sentiment and customer satisfaction\n",
        "Step 3: Identify which product performs better in different categories\n",
        "Step 4: Provide a comparative summary\n",
        "\n",
        "Product Summaries:\n",
        "{product_summaries}\n",
        "\n",
        "Please provide a comparative analysis following this chain of thought.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = openai_client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert at comparing products based on customer reviews.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=1500,\n",
        "            temperature=0.3\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        return f\"Error generating comparison: {str(e)}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f56218b6",
      "metadata": {
        "id": "f56218b6"
      },
      "source": [
        "## Example 1: List Available Firecrawl Tools\n",
        "\n",
        "First, let's see what tools are available from the Firecrawl MCP server:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc4f1ee6",
      "metadata": {
        "id": "cc4f1ee6",
        "outputId": "93c26bd7-0b52-4f9c-ad6b-7324cd3a5bad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Process group termination failed for PID 90307: [Errno 1] Operation not permitted, falling back to simple terminate\n"
          ]
        },
        {
          "ename": "McpError",
          "evalue": "Connection closed",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mMcpError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tools\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Run the async function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m tools = \u001b[38;5;28;01mawait\u001b[39;00m list_available_tools()\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mlist_available_tools\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlist_available_tools\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m FirecrawlClient(FIRECRAWL_API_KEY) \u001b[38;5;28;01mas\u001b[39;00m client:\n\u001b[32m      3\u001b[39m         tools = \u001b[38;5;28;01mawait\u001b[39;00m client.list_tools()\n\u001b[32m      4\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAvailable Firecrawl Tools:\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mFirecrawlClient.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mself\u001b[39m.session = \u001b[38;5;28;01mawait\u001b[39;00m ClientSession(\n\u001b[32m     23\u001b[39m     stdio_transport[\u001b[32m0\u001b[39m], \n\u001b[32m     24\u001b[39m     stdio_transport[\u001b[32m1\u001b[39m]\n\u001b[32m     25\u001b[39m ).\u001b[34m__aenter__\u001b[39m()\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Initialize the session\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.session.initialize()\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Kissflow/prompt2finetune/.venv/lib/python3.13/site-packages/mcp/client/session.py:152\u001b[39m, in \u001b[36mClientSession.initialize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    140\u001b[39m elicitation = (\n\u001b[32m    141\u001b[39m     types.ElicitationCapability() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._elicitation_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _default_elicitation_callback \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    142\u001b[39m )\n\u001b[32m    143\u001b[39m roots = (\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# TODO: Should this be based on whether we\u001b[39;00m\n\u001b[32m    145\u001b[39m     \u001b[38;5;66;03m# _will_ send notifications, or only whether\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    149\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    150\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send_request(\n\u001b[32m    153\u001b[39m     types.ClientRequest(\n\u001b[32m    154\u001b[39m         types.InitializeRequest(\n\u001b[32m    155\u001b[39m             params=types.InitializeRequestParams(\n\u001b[32m    156\u001b[39m                 protocolVersion=types.LATEST_PROTOCOL_VERSION,\n\u001b[32m    157\u001b[39m                 capabilities=types.ClientCapabilities(\n\u001b[32m    158\u001b[39m                     sampling=sampling,\n\u001b[32m    159\u001b[39m                     elicitation=elicitation,\n\u001b[32m    160\u001b[39m                     experimental=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    161\u001b[39m                     roots=roots,\n\u001b[32m    162\u001b[39m                 ),\n\u001b[32m    163\u001b[39m                 clientInfo=\u001b[38;5;28mself\u001b[39m._client_info,\n\u001b[32m    164\u001b[39m             ),\n\u001b[32m    165\u001b[39m         )\n\u001b[32m    166\u001b[39m     ),\n\u001b[32m    167\u001b[39m     types.InitializeResult,\n\u001b[32m    168\u001b[39m )\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.protocolVersion \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_PROTOCOL_VERSIONS:\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported protocol version from the server: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.protocolVersion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Kissflow/prompt2finetune/.venv/lib/python3.13/site-packages/mcp/shared/session.py:286\u001b[39m, in \u001b[36mBaseSession.send_request\u001b[39m\u001b[34m(self, request, result_type, request_read_timeout_seconds, metadata, progress_callback)\u001b[39m\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m McpError(\n\u001b[32m    275\u001b[39m         ErrorData(\n\u001b[32m    276\u001b[39m             code=httpx.codes.REQUEST_TIMEOUT,\n\u001b[32m   (...)\u001b[39m\u001b[32m    282\u001b[39m         )\n\u001b[32m    283\u001b[39m     )\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response_or_error, JSONRPCError):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m McpError(response_or_error.error)\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result_type.model_validate(response_or_error.result)\n",
            "\u001b[31mMcpError\u001b[39m: Connection closed"
          ]
        }
      ],
      "source": [
        "async def list_available_tools():\n",
        "    async with FirecrawlClient(FIRECRAWL_API_KEY) as client:\n",
        "        tools = await client.list_tools()\n",
        "        print(\"Available Firecrawl Tools:\")\n",
        "        print(\"=\" * 50)\n",
        "        for tool in tools:\n",
        "            print(f\"\\nTool: {tool.name}\")\n",
        "            print(f\"Description: {tool.description}\")\n",
        "            if hasattr(tool, 'inputSchema'):\n",
        "                print(f\"Input Schema: {json.dumps(tool.inputSchema, indent=2)}\")\n",
        "        return tools\n",
        "\n",
        "# Run the async function\n",
        "tools = await list_available_tools()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "909bf0dc",
      "metadata": {
        "id": "909bf0dc"
      },
      "source": [
        "## Example 2: Single Amazon Product Review Fetch\n",
        "\n",
        "Scrape an Amazon product page and generate a brief summary using chain-of-thought prompting:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f055ecf",
      "metadata": {
        "id": "2f055ecf"
      },
      "source": [
        "async def fetch_single_product_reviews():\n",
        "    # Example Amazon product URL (replace with actual product URL)\n",
        "    amazon_url = \"https://www.amazon.com/dp/B08N5WRWNW\"  # Example: Echo Dot\n",
        "    \n",
        "    async with FirecrawlClient(FIRECRAWL_API_KEY) as client:\n",
        "        print(f\"Scraping Amazon product: {amazon_url}\")\n",
        "        print(\"=\" * 60)\n",
        "        \n",
        "        try:\n",
        "            # Scrape the URL\n",
        "            result = await client.scrape_url(amazon_url, extract_reviews=True)\n",
        "            print(\"Raw scraped content preview:\")\n",
        "            print(\"-\" * 40)\n",
        "            if isinstance(result, dict) and 'content' in result:\n",
        "                print(result['content'][:500] + \"...\" if len(result['content']) > 500 else result['content'])\n",
        "            else:\n",
        "                print(result)\n",
        "            \n",
        "            # Extract reviews from scraped content\n",
        "            reviews = client.extract_amazon_reviews(result)\n",
        "            print(f\"\\nExtracted {len(reviews)} reviews\")\n",
        "            print(\"-\" * 40)\n",
        "            \n",
        "            # Display first few reviews\n",
        "            for i, review in enumerate(reviews[:3]):\n",
        "                print(f\"\\nReview {i+1}:\")\n",
        "                print(f\"Text: {review['text'][:200]}...\")\n",
        "                if review['rating']:\n",
        "                    print(f\"Rating: {review['rating']}\")\n",
        "            \n",
        "            # Generate brief summary using chain-of-thought\n",
        "            print(\"\\n\" + \"=\" * 60)\n",
        "            print(\"CHAIN-OF-THOUGHT SUMMARY:\")\n",
        "            print(\"=\" * 60)\n",
        "            summary = summarize_reviews_chain_of_thought(reviews, detail_level=\"brief\")\n",
        "            print(summary)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error scraping or analyzing reviews: {e}\")\n",
        "\n",
        "# Run the async function\n",
        "await fetch_single_product_reviews()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fc91629",
      "metadata": {
        "id": "1fc91629"
      },
      "source": [
        "## Example 3: Detailed Review Analysis with Chain-of-Thought\n",
        "\n",
        "Perform a comprehensive analysis of the same product using detailed chain-of-thought prompting:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aebbc110",
      "metadata": {
        "id": "aebbc110"
      },
      "outputs": [],
      "source": [
        "async def fetch_ml_frameworks_docs():\n",
        "    frameworks = [\n",
        "        (\"torch\", \"transformer model\"),\n",
        "        (\"tensorflow\", \"keras\"),\n",
        "        (\"jax\", \"neural network\"),\n",
        "        (\"accelerate\", \"distributed training\"),\n",
        "        (\"peft\", \"LoRA fine-tuning\"),\n",
        "        (\"bitsandbytes\", \"quantization\"),\n",
        "        (\"trl\", \"RLHF training\"),\n",
        "    ]\n",
        "\n",
        "    async with Context7Client(CONTEXT7_API_KEY) as client:\n",
        "        for framework, query in frameworks:\n",
        "            print(f\"\\n{'=' * 60}\")\n",
        "            print(f\"Framework: {framework}\")\n",
        "            print(f\"Query: {query}\")\n",
        "            print('=' * 60)\n",
        "            try:\n",
        "                result = await client.get_documentation(framework, query=query)\n",
        "                print(result)\n",
        "            except Exception as e:\n",
        "                print(f\"Error fetching documentation: {e}\")\n",
        "            print(\"\\n\")\n",
        "\n",
        "# Run the async function\n",
        "await fetch_ml_frameworks_docs()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "258e0175",
      "metadata": {
        "id": "258e0175"
      },
      "source": [
        "## Example 4: Multiple Products Comparison\n",
        "\n",
        "Compare reviews from multiple Amazon products using chain-of-thought analysis:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "577d4d96",
      "metadata": {
        "id": "577d4d96"
      },
      "outputs": [],
      "source": [
        "async def compare_multiple_products():\n",
        "    # Example Amazon product URLs (replace with actual product URLs)\n",
        "    product_urls = [\n",
        "        \"https://www.amazon.com/dp/B08N5WRWNW\",  # Echo Dot\n",
        "        \"https://www.amazon.com/dp/B07XJ8C8F7\",  # Echo Show\n",
        "        \"https://www.amazon.com/dp/B07FZ8S74R\"   # Echo Plus\n",
        "    ]\n",
        "\n",
        "    product_summaries = []\n",
        "\n",
        "    async with FirecrawlClient(FIRECRAWL_API_KEY) as client:\n",
        "        for i, url in enumerate(product_urls, 1):\n",
        "            print(f\"\\n{'=' * 70}\")\n",
        "            print(f\"Product {i}: {url}\")\n",
        "            print('=' * 70)\n",
        "\n",
        "            try:\n",
        "                # Scrape the URL\n",
        "                result = await client.scrape_url(url, extract_reviews=True)\n",
        "                reviews = client.extract_amazon_reviews(result)\n",
        "\n",
        "                print(f\"Found {len(reviews)} reviews\")\n",
        "\n",
        "                # Generate summary for this product\n",
        "                summary = summarize_reviews_chain_of_thought(reviews, detail_level=\"brief\")\n",
        "                product_summaries.append(f\"Product {i} Summary:\\n{summary}\")\n",
        "\n",
        "                print(f\"\\nProduct {i} Summary:\")\n",
        "                print(\"-\" * 50)\n",
        "                print(summary)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error analyzing product {i}: {e}\")\n",
        "                product_summaries.append(f\"Product {i}: Error - {str(e)}\")\n",
        "\n",
        "        # Compare all products\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"COMPARATIVE ANALYSIS\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "        comparison = compare_products_summary(\"\\n\\n\".join(product_summaries))\n",
        "        print(comparison)\n",
        "\n",
        "# Run the async function\n",
        "await compare_multiple_products()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e6036ff",
      "metadata": {
        "id": "5e6036ff"
      },
      "source": [
        "## Example 5: Interactive Review Fetcher\n",
        "\n",
        "Create a reusable function to fetch and summarize reviews for any Amazon product:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c6ae5ad",
      "metadata": {
        "id": "0c6ae5ad"
      },
      "outputs": [],
      "source": [
        "async def fetch_and_summarize_reviews(amazon_url, detail_level=\"brief\"):\n",
        "    \"\"\"\n",
        "    Interactive function to fetch and summarize reviews for any Amazon product.\n",
        "\n",
        "    Args:\n",
        "        amazon_url (str): Amazon product URL\n",
        "        detail_level (str): \"brief\" or \"detailed\" summary level\n",
        "\n",
        "    Returns:\n",
        "        dict: Contains reviews, summary, and metadata\n",
        "    \"\"\"\n",
        "    print(f\"🔍 Fetching reviews from: {amazon_url}\")\n",
        "    print(f\"📊 Analysis level: {detail_level}\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    async with FirecrawlClient(FIRECRAWL_API_KEY) as client:\n",
        "        try:\n",
        "            # Scrape the URL\n",
        "            result = await client.scrape_url(amazon_url, extract_reviews=True)\n",
        "            reviews = client.extract_amazon_reviews(result)\n",
        "\n",
        "            print(f\"✅ Successfully extracted {len(reviews)} reviews\")\n",
        "\n",
        "            if not reviews:\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"error\": \"No reviews found\",\n",
        "                    \"reviews\": [],\n",
        "                    \"summary\": \"No reviews available for analysis\"\n",
        "                }\n",
        "\n",
        "            # Generate summary using chain-of-thought\n",
        "            print(f\"\\n🤖 Generating {detail_level} summary using chain-of-thought...\")\n",
        "            summary = summarize_reviews_chain_of_thought(reviews, detail_level=detail_level)\n",
        "\n",
        "            print(f\"\\n📝 Summary ({detail_level}):\")\n",
        "            print(\"-\" * 50)\n",
        "            print(summary)\n",
        "\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"reviews\": reviews,\n",
        "                \"summary\": summary,\n",
        "                \"review_count\": len(reviews),\n",
        "                \"detail_level\": detail_level\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error: {e}\")\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"error\": str(e),\n",
        "                \"reviews\": [],\n",
        "                \"summary\": None\n",
        "            }\n",
        "\n",
        "# Example usage:\n",
        "# result = await fetch_and_summarize_reviews(\"https://www.amazon.com/dp/B08N5WRWNW\", \"brief\")\n",
        "# result = await fetch_and_summarize_reviews(\"https://www.amazon.com/dp/B08N5WRWNW\", \"detailed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6001f9f4",
      "metadata": {
        "id": "6001f9f4"
      },
      "source": [
        "## Notes and Best Practices\n",
        "\n",
        "1. **API Keys**: Make sure to replace `YOUR_FIRECRAWL_API_KEY` and `YOUR_OPENAI_API_KEY` with your actual API keys\n",
        "2. **Error Handling**: The examples include try-catch blocks to handle cases where scraping might fail or reviews might not be available\n",
        "3. **Async/Await**: All MCP operations are asynchronous, so use `await` in Jupyter notebooks or async functions\n",
        "4. **Resource Management**: The `FirecrawlClient` uses context managers to ensure proper cleanup of connections\n",
        "5. **Chain-of-Thought Prompting**: The summarization uses structured prompting to ensure the AI follows a logical reasoning process\n",
        "6. **Rate Limiting**: Be mindful of API rate limits for both Firecrawl and OpenAI services\n",
        "7. **Amazon URL Format**: Ensure Amazon URLs are in the correct format (e.g., https://www.amazon.com/dp/PRODUCT_ID)\n",
        "\n",
        "## Server Configuration\n",
        "\n",
        "The Firecrawl MCP server is configured with:\n",
        "```json\n",
        "{\n",
        "  \"mcpServers\": {\n",
        "    \"firecrawl-mcp\": {\n",
        "      \"command\": \"npx\",\n",
        "      \"args\": [\"-y\", \"firecrawl-mcp\"],\n",
        "      \"env\": {\n",
        "        \"FIRECRAWL_API_KEY\": \"YOUR-API-KEY\"\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "This configuration is automatically handled by the `FirecrawlClient` class in this notebook.\n",
        "\n",
        "## Chain-of-Thought Prompting Benefits\n",
        "\n",
        "The chain-of-thought approach provides several advantages:\n",
        "- **Structured Analysis**: Forces the AI to follow a logical sequence of steps\n",
        "- **Transparency**: Shows the reasoning process behind conclusions\n",
        "- **Better Accuracy**: Step-by-step analysis typically produces more accurate results\n",
        "- **Comprehensive Coverage**: Ensures all important aspects are considered\n",
        "- **Debugging**: Easier to identify where analysis might have gone wrong\n",
        "\n",
        "## Usage Examples\n",
        "\n",
        "```python\n",
        "# Brief summary\n",
        "result = await fetch_and_summarize_reviews(\"https://www.amazon.com/dp/B08N5WRWNW\", \"brief\")\n",
        "\n",
        "# Detailed analysis\n",
        "result = await fetch_and_summarize_reviews(\"https://www.amazon.com/dp/B08N5WRWNW\", \"detailed\")\n",
        "\n",
        "# Compare multiple products\n",
        "await compare_multiple_products()\n",
        "```\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}